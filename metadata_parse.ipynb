{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-08T08:31:33.459721Z",
     "start_time": "2025-07-08T08:31:33.456495Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from ete3 import NCBITaxa\n",
    "import biothings_client as bt\n",
    "import tarfile\n",
    "import gzip"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T07:36:31.820753Z",
     "start_time": "2025-07-08T07:36:31.817900Z"
    }
   },
   "cell_type": "code",
   "source": "os.getcwd()",
   "id": "e256ce5a2cabace6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bailinzhang/Documents/Wu_Lab/Projects/GMMAD2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T07:36:31.996810Z",
     "start_time": "2025-07-08T07:36:31.838493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "micro_disease_df = pd.read_csv(os.path.join(\"downloads\", \"disease_species.csv\"), low_memory=False)\n",
    "micro_meta_df = pd.read_csv(os.path.join(\"downloads\", \"micro_metabolic.csv\"), low_memory=False)\n",
    "meta_gene_df = pd.read_csv(os.path.join(\"downloads\", \"meta_gene_net.csv\"), low_memory=False)"
   ],
   "id": "b2b431d3bb874335",
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 24 fields in line 4, saw 29\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mParserError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m micro_disease_df = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m.\u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdownloads\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdisease_species.csv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlow_memory\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m micro_meta_df = pd.read_csv(os.path.join(\u001B[33m\"\u001B[39m\u001B[33mdownloads\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmicro_metabolic.csv\u001B[39m\u001B[33m\"\u001B[39m), low_memory=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m      3\u001B[39m meta_gene_df = pd.read_csv(os.path.join(\u001B[33m\"\u001B[39m\u001B[33mdownloads\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmeta_gene_net.csv\u001B[39m\u001B[33m\"\u001B[39m), low_memory=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Wu_Lab/Projects/GMMAD2/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Wu_Lab/Projects/GMMAD2/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[32m    625\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[32m--> \u001B[39m\u001B[32m626\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Wu_Lab/Projects/GMMAD2/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001B[39m, in \u001B[36mTextFileReader.read\u001B[39m\u001B[34m(self, nrows)\u001B[39m\n\u001B[32m   1916\u001B[39m nrows = validate_integer(\u001B[33m\"\u001B[39m\u001B[33mnrows\u001B[39m\u001B[33m\"\u001B[39m, nrows)\n\u001B[32m   1917\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1918\u001B[39m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[32m   1919\u001B[39m     (\n\u001B[32m   1920\u001B[39m         index,\n\u001B[32m   1921\u001B[39m         columns,\n\u001B[32m   1922\u001B[39m         col_dict,\n\u001B[32m-> \u001B[39m\u001B[32m1923\u001B[39m     ) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[32m   1924\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[32m   1925\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1926\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1927\u001B[39m     \u001B[38;5;28mself\u001B[39m.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Wu_Lab/Projects/GMMAD2/.venv/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:239\u001B[39m, in \u001B[36mCParserWrapper.read\u001B[39m\u001B[34m(self, nrows)\u001B[39m\n\u001B[32m    236\u001B[39m         data = _concatenate_chunks(chunks)\n\u001B[32m    238\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m239\u001B[39m         data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_reader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    240\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._first_chunk:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mparsers.pyx:820\u001B[39m, in \u001B[36mpandas._libs.parsers.TextReader.read\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mparsers.pyx:914\u001B[39m, in \u001B[36mpandas._libs.parsers.TextReader._read_rows\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mparsers.pyx:891\u001B[39m, in \u001B[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mparsers.pyx:2061\u001B[39m, in \u001B[36mpandas._libs.parsers.raise_parser_error\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mParserError\u001B[39m: Error tokenizing data. C error: Expected 24 fields in line 4, saw 29\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T07:36:37.577459Z",
     "start_time": "2025-07-08T07:36:37.573284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(os.path.join(\"downloads\", \"disease_species.csv\"), \"r\") as f:\n",
    "    for i, line in enumerate(f, start=1):\n",
    "        if i == 4:\n",
    "            print(len(line.strip().split(\",\")))\n",
    "            print(line)\n",
    "            break"
   ],
   "id": "b8ca0bf20a5b40b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "3,D009765,Obesity,Azorhizobium caulinodans,species,7,0,0,0,0,D006262,Health,3,0.029020807,0.0248571,0.031027083,-0.0248571,Decrease,A status with BODY WEIGHT that is grossly above the acceptable or desirable weight, usually due to accumulation of excess FATS in the body. The standards may vary with age, sex, genetic or cultural background. In the BODY MASS INDEX, a BMI greater than 30.0 kg/m2 is considered obese, and a BMI greater than 40.0 kg/m2 is considered morbidly obese (MORBID OBESITY).,Pseudomonadota,Alphaproteobacteria,Hyphomicrobiales,Xanthobacteraceae,Azorhizobium\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T07:37:01.402096Z",
     "start_time": "2025-07-08T07:37:01.398918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def line_generator(in_file):\n",
    "    \"\"\"generates lines from a CSV file, yielding each line as a list of strings\n",
    "    This function opens the specified CSV file, skips the header row, and yields each subsequent line as a list of strings.\n",
    "\n",
    "    :param in_file: The path to the CSV file.\n",
    "    :return: An iterator that yields each line of the CSV file as a list of strings.\n",
    "    \"\"\"\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        reader = csv.reader(in_f)\n",
    "        next(reader)\n",
    "        for line in reader:\n",
    "            yield line"
   ],
   "id": "3f1e800017f49fc0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T07:37:36.733249Z",
     "start_time": "2025-07-08T07:37:36.726348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "micro_disease_path = os.path.join(\"downloads\", \"disease_species.csv\")\n",
    "micro_disease = line_generator(micro_disease_path)\n",
    "for i, line in enumerate(micro_disease):\n",
    "    if i == 3:\n",
    "        print(len(line))\n",
    "        print(line)\n",
    "    elif i == 15:\n",
    "        print(len(line))\n",
    "        print(line)\n",
    "    elif i == 16:\n",
    "        print(len(line))\n",
    "        print(line)\n",
    "        break"
   ],
   "id": "e08486b7b35705ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "['4', 'D008103', 'Liver Cirrhosis', 'Azorhizobium caulinodans', 'species', '7', '0', '0', '0', '0', 'D006262', 'Health', '3', '0.029020807', '0.0248571', '0.031027083', '-0.0248571', 'Decrease', 'Liver disease in which the normal microcirculation', ' the gross vascular anatomy', ' and the hepatic architecture have been variably destroyed and altered with fibrous septa surrounding regenerated or regenerating parenchymal nodules.', 'Pseudomonadota', 'Alphaproteobacteria', 'Hyphomicrobiales', 'Xanthobacteraceae', 'Azorhizobium']\n",
      "30\n",
      "['16', 'D001172', 'Arthritis', ' Rheumatoid', 'Azorhizobium caulinodans', 'species', '7', '0', '0', '0', '0', 'D006262', 'Health', '3', '0.029020807', '0.0248571', '0.031027083', '-0.0248571', 'Decrease', 'A chronic systemic disease', ' primarily of the joints', ' marked by inflammatory changes in the synovial membranes and articular structures', ' widespread fibrinoid degeneration of the collagen fibers in mesenchymal tissues', ' and by atrophy and rarefaction of bony structures. Etiology is unknown', ' but autoimmune mechanisms have been implicated.', 'Pseudomonadota', 'Alphaproteobacteria', 'Hyphomicrobiales', 'Xanthobacteraceae', 'Azorhizobium']\n",
      "27\n",
      "['17', 'D043183', 'Irritable Bowel Syndrome', 'Azorhizobium caulinodans', 'species', '7', '0', '0', '0', '0', 'D006262', 'Health', '3', '0.029020807', '0.0248571', '0.031027083', '-0.0248571', 'Decrease', 'A disorder with chronic or recurrent colonic symptoms without a clearcut etiology. This condition is characterized by chronic or recurrent ABDOMINAL PAIN', ' bloating', ' MUCUS in FECES', ' and an erratic disturbance of DEFECATION.', 'Pseudomonadota', 'Alphaproteobacteria', 'Hyphomicrobiales', 'Xanthobacteraceae', 'Azorhizobium']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T07:43:02.376350Z",
     "start_time": "2025-07-08T07:43:02.369486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def line_generator(in_file):\n",
    "    \"\"\"Yield each CSV line as a list of exactly 24 fields,\n",
    "    rejoining commas inside the 'disease' and 'disease_info' columns.\n",
    "    \"\"\"\n",
    "    EXPECTED_COUNT = 24\n",
    "    HEAD_COUNT = 2\n",
    "    TAIL_COUNT = 5\n",
    "    FIXED_COUNT = 15\n",
    "\n",
    "    with open(in_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        header = next(f).rstrip(\"\\n\").split(\",\")\n",
    "        print(f\"Header column names:{header}\")\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            parts = [part.strip() for part in line.split(\",\")]\n",
    "            if len(parts) == EXPECTED_COUNT:\n",
    "                yield parts\n",
    "            else:\n",
    "                alteration_idx = next(i for i, p in enumerate(parts) if p in (\"Increase\", \"Decrease\"))\n",
    "                head = parts[:HEAD_COUNT]\n",
    "                fixed_start = alteration_idx - (FIXED_COUNT - 1)\n",
    "                disease = \",\".join(parts[2:fixed_start])\n",
    "                fixed = parts[fixed_start: alteration_idx + 1]\n",
    "                disease_info = \",\".join(parts[alteration_idx + 1: len(parts) - TAIL_COUNT])\n",
    "                tail = parts[-TAIL_COUNT:]\n",
    "                new_line = head + [disease] + fixed + [disease_info] + tail\n",
    "                assert len(new_line) == EXPECTED_COUNT, f\"Expected {EXPECTED_COUNT} cols, got {len(new_line)}\"\n",
    "                yield new_line\n"
   ],
   "id": "3558bb5e152b6ec3",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T07:43:03.782681Z",
     "start_time": "2025-07-08T07:43:03.764766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "micro_disease = line_generator(micro_disease_path)\n",
    "for i, line in enumerate(micro_disease):\n",
    "    if i == 3:\n",
    "        print(len(line))\n",
    "        print(line)\n",
    "    elif i == 15:\n",
    "        print(len(line))\n",
    "        print(line)\n",
    "    elif i == 16:\n",
    "        print(len(line))\n",
    "        print(line)\n",
    "        break"
   ],
   "id": "c26dd3d2f50be754",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header column names:['id', 'disease_id', 'disease', 'organism', 'level', 'species_id', 'disease_samples', 'disease_mean', 'disease_median', 'disease_sd', 'health_id', 'health', 'health_samples', 'health_mean', 'health_median', 'health_sd', 'change', 'alteration', 'disease_info', 'phylum', 'class', 'order', 'family', 'genus']\n",
      "24\n",
      "['5', 'D001327', 'Autoimmune Diseases', 'Azorhizobium caulinodans', 'species', '7', '0', '0', '0', '0', 'D006262', 'Health', '3', '0.029020807', '0.0248571', '0.031027083', '-0.0248571', 'Decrease', 'Disorders that are characterized by the production of antibodies that react with host tissues or immune effector cells that are autoreactive to endogenous peptides.', 'Pseudomonadota', 'Alphaproteobacteria', 'Hyphomicrobiales', 'Xanthobacteraceae', 'Azorhizobium']\n",
      "24\n",
      "['17', 'D043183', 'Irritable Bowel Syndrome', 'Azorhizobium caulinodans', 'species', '7', '0', '0', '0', '0', 'D006262', 'Health', '3', '0.029020807', '0.0248571', '0.031027083', '-0.0248571', 'Decrease', 'A disorder with chronic or recurrent colonic symptoms without a clearcut etiology. This condition is characterized by chronic or recurrent ABDOMINAL PAIN,bloating,MUCUS in FECES,and an erratic disturbance of DEFECATION.', 'Pseudomonadota', 'Alphaproteobacteria', 'Hyphomicrobiales', 'Xanthobacteraceae', 'Azorhizobium']\n",
      "24\n",
      "['18', 'D003093', 'Colitis,Ulcerative', 'Azorhizobium caulinodans', 'species', '7', '0', '0', '0', '0', 'D006262', 'Health', '3', '0.029020807', '0.0248571', '0.031027083', '-0.0248571', 'Decrease', 'Inflammation of the COLON that is predominantly confined to the MUCOSA. Its major symptoms include DIARRHEA,rectal BLEEDING,the passage of MUCUS,and ABDOMINAL PAIN.', 'Pseudomonadota', 'Alphaproteobacteria', 'Hyphomicrobiales', 'Xanthobacteraceae', 'Azorhizobium']\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e361aa30e28b8d5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:09:01.910794Z",
     "start_time": "2025-07-08T08:09:00.694796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "taxids = [line[5] for line in line_generator(micro_disease_path)]\n",
    "print(len(set(taxids)))"
   ],
   "id": "abd2a2d2f6f46681",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header column names:['id', 'disease_id', 'disease', 'organism', 'level', 'species_id', 'disease_samples', 'disease_mean', 'disease_median', 'disease_sd', 'health_id', 'health', 'health_samples', 'health_mean', 'health_median', 'health_sd', 'change', 'alteration', 'disease_info', 'phylum', 'class', 'order', 'family', 'genus']\n",
      "6966\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:11:55.195992Z",
     "start_time": "2025-07-08T08:11:55.192059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_taxon_info(f_path) -> list:\n",
    "    \"\"\"retrieves taxonomic information for a given list of taxon IDs from disease_species.csv\n",
    "\n",
    "    This function reads taxon IDs, removes duplicates, and queries taxonomic info from biothings_client\n",
    "    to retrieve detailed taxonomic information including scientific name, parent taxid, lineage, and rank.\n",
    "\n",
    "    :param f_path: Path to disease_species.csv containing the taxids.\n",
    "    :return: A list of dictionaries containing taxonomic information.\n",
    "    \"\"\"\n",
    "    taxids = [line[5] for line in line_generator(f_path)]\n",
    "    taxids = set(taxids)\n",
    "    t = bt.get_client(\"taxon\")\n",
    "    taxon_info = t.gettaxa(taxids, fields=[\"scientific_name\", \"parent_taxid\", \"lineage\", \"rank\"])\n",
    "    return taxon_info"
   ],
   "id": "7869af7cbbb243e5",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:12:12.206256Z",
     "start_time": "2025-07-08T08:11:56.020872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "notfound = [\n",
    "    taxon[\"query\"]\n",
    "    for taxon in get_taxon_info(micro_disease_path)\n",
    "    if \"notfound\" in taxon.keys()\n",
    "]"
   ],
   "id": "304667571d9b9e72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header column names:['id', 'disease_id', 'disease', 'organism', 'level', 'species_id', 'disease_samples', 'disease_mean', 'disease_median', 'disease_sd', 'health_id', 'health', 'health_samples', 'health_mean', 'health_median', 'health_sd', 'change', 'alteration', 'disease_info', 'phylum', 'class', 'order', 'family', 'genus']\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:12:17.822880Z",
     "start_time": "2025-07-08T08:12:17.818363Z"
    }
   },
   "cell_type": "code",
   "source": "len(notfound)",
   "id": "9013cc98a088bea5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:17:59.618767Z",
     "start_time": "2025-07-08T08:17:05.997943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ncbi = NCBITaxa()\n",
    "ncbi.update_taxonomy_database()"
   ],
   "id": "a61dcc02f6cbded8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local taxdump.tar.gz seems up-to-date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading node names...\n",
      "2684668 names loaded.\n",
      "418698 synonyms loaded.\n",
      "Loading nodes...\n",
      "2684668 nodes loaded.\n",
      "Linking nodes...\n",
      "Tree is loaded.\n",
      "Updating database: /Users/bailinzhang/.etetoolkit/taxa.sqlite ...\n",
      " 2684000 generating entries... \n",
      "Uploading to /Users/bailinzhang/.etetoolkit/taxa.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting synonyms:      60000 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting taxids:       40000   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting taxids:       2680000    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:55:10.626481Z",
     "start_time": "2025-07-08T08:55:10.618764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_merged_from_tar(tar_gz_path, f_name=\"merged.dmp\"):\n",
    "    \"\"\"Parse 'merged.dmp' of taxdump.tar.gz downloaded by ete3.\n",
    "    Returns a dict {old_taxid: new_taxid}.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(tar_gz_path):\n",
    "        ncbi = NCBITaxa()\n",
    "        ncbi.update_taxonomy_database()\n",
    "\n",
    "    taxid_mapping = {}\n",
    "    with tarfile.open(tar_gz_path, 'r:gz') as tar:\n",
    "        f = tar.getmember(f_name)\n",
    "        with tar.extractfile(f) as fp:\n",
    "            for line in fp:\n",
    "                parts = line.decode('utf-8').split('\\t')\n",
    "                old, new = parts[0], parts[2]\n",
    "                taxid_mapping[old] = new\n",
    "    return taxid_mapping"
   ],
   "id": "31e4a3ec7c230a54",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:55:11.030664Z",
     "start_time": "2025-07-08T08:55:11.028140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_current_taxid(old_taxids, merged_mapping):\n",
    "    taxid_mapping = {}\n",
    "    for old_taxid in old_taxids:\n",
    "        taxid_mapping[old_taxid] = merged_mapping[old_taxid]\n",
    "    return taxid_mapping"
   ],
   "id": "acc8a1a8670b9fa2",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:55:12.669144Z",
     "start_time": "2025-07-08T08:55:12.186832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapping = load_merged_from_tar(\"taxdump.tar.gz\")\n",
    "mapped_taxid = get_current_taxid(notfound, mapping)"
   ],
   "id": "6e20f0d6aa8cbe34",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:52:03.230492Z",
     "start_time": "2025-07-08T08:52:03.223876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if \"194866\" in mapping:\n",
    "    print(\"194866 is in the mapping\")\n",
    "    print(f\"current taxid for 194866: {mapping['194866']}\")\n",
    "else:\n",
    "    print(\"194866 is not in the mapping\")"
   ],
   "id": "962bd7beb66f230b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194866 is in the mapping\n",
      "current taxid for 194866: 46624\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T08:55:39.272296Z",
     "start_time": "2025-07-08T08:55:39.264431Z"
    }
   },
   "cell_type": "code",
   "source": "len(mapped_taxid)",
   "id": "db5919055a656b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "852ff1c20351b0c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
